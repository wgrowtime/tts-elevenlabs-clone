# ğŸ—£ï¸ Real-Time Text-to-Speech Streaming Service (ElevenLabs Clone)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yrshanker/tts-elevenlabs-clone/blob/main/TTS_final_submission.ipynb)
![Python](https://img.shields.io/badge/Python-3.10-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-async-green)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

---

### ğŸš€ Overview
This project implements a **low-latency, open-weight Text-to-Speech (TTS)** engine inspired by ElevenLabs' real-time streaming API.  
Itâ€™s fully contained in a **Google Colab notebook** using **open-source models only** â€” no cloud-based APIs like Azure or ElevenLabs are used.

The notebook exposes a **bidirectional WebSocket server** to stream JSON text chunks in and **44.1 kHz audio** chunks out with real-time playback and **character-level timestamp alignment**.

---

### âœ¨ Key Features
- âš¡ **~550 ms p50 latency** from first input to first audio output  
- ğŸ§ **44.1 kHz / 16-bit mono PCM audio** streamed via Base64 JSON  
- ğŸ”  **Character-level alignment** (â‰¤ Â±120 ms error) for real-time captions  
- ğŸ§® **Math-aware TTS**: interprets LaTeX and symbolic notation in speech  
- ğŸ§± **End-to-end Colab deployment** using open-weight TTS models  
- ğŸ§© **Coqui XTTS, Bark, and SpeechT5** support  

---

### ğŸ§  Architecture
```text
Client (Colab / WebSocket)
   â”‚
   â”œâ”€â”€â–º JSON stream {"text": "...", "flush": bool}
   â”‚
WebSocket Server (FastAPI + asyncio)
   â”œâ”€â”€ Text buffer aggregation
   â”œâ”€â”€ Model inference (open-weight TTS)
   â”œâ”€â”€ Alignment estimation
   â””â”€â”€â–º {"audio": <Base64>, "alignment": {...}}
